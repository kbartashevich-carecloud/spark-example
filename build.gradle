apply plugin: 'scala'configurations {                                                          provided}sourceSets {                                                             main.compileClasspath += configurations.provided}repositories {  mavenCentral()}version = '0.1.0' ScalaCompileOptions.metaClass.daemonServer = true ScalaCompileOptions.metaClass.fork = true ScalaCompileOptions.metaClass.useAnt = false ScalaCompileOptions.metaClass.useCompileDaemon = falsedependencies {  runtime "org.scala-lang:scala-compiler:2.12.7"  runtime "org.apache.spark:spark-core_2.12:2.4.0"  runtime "org.apache.spark:spark-sql_2.12:2.4.0"  compile "org.scala-lang:scala-library:2.12.7"  provided "org.apache.spark:spark-core_2.12:2.4.0"                     provided "org.apache.spark:spark-sql_2.12:2.4.0"}jar {  dependsOn configurations.runtime  from {    (configurations.runtime - configurations.provided).collect {            it.isDirectory() ? it : zipTree(it)    }  } {    exclude "META-INF/*.SF"    exclude "META-INF/*.DSA"    exclude "META-INF/*.RSA"  }}task repl(type:JavaExec) {                                            4    main = "scala.tools.nsc.MainGenericRunner"    classpath = sourceSets.main.runtimeClasspath    standardInput System.in    args '-usejavacp'}